---
title: "Advanced A/B Testing"
subtitle: "When you need to make a decision, go Bayesian"
author: "Elea McDonnell Feit"
date: "6/10/2019"
output: ioslides_presentation
widescreen: yes
---

```{r setup, include=FALSE}
library(rstan)
```


# Test & Roll

## Typical A/B email test setup screen


## Hypothesis testing is a bad fit for tactical tests in marketing

1. Hypothesis tests focus on minimizing Type I error
    - Doesn't matter when we are deciding which treatment to deploy 

2. Populations are limited and hypothesis test 
    - Sample size formulas will suggest sample sizes larger than the population
    
3. When a hypothesis test is insignificant, it doesn't tell you what to do. 
    - Choose randomly? That doesn't make sense. 
    
4. Doesn't allow for unequal group sizes
    - But we see these all the time in media holdout testing
    
    
## A/B tests as a decision problem


## Optimal sample size
For the case where response is normally distributed with a symmetric normal prior on the means, we derive an optimal sample size formula. 

$$n_1 = n_2 = $$
If the priors are different (eg a holdout test), the optimal sample sizes can be found numerically.


## Procedure
1. Come up with priors (from past data, if you've got it)
2. Use the priors to compute the optimal sample size
3. Run the test
4. Choose the treatment with the higher posterior 


## Hierarchical model for past experiments {.smaller}
```{stan}
// Stan code for Lewis and Rao 2015 data
// L&R only report the mean and standard deviation for the control group for each experiment
data {
  int<lower=1> nexpt; // number of experiments
  real<lower=2> nobs[nexpt]; // sample size for control group
  real ybar[nexpt]; // observed mean for control group
  real<lower=0> s[nexpt]; // observed standard deviation for experiment (pooled)
}
parameters {
real m[nexpt]; // true mean for control group in experiment
real mu; // mean across experiments
real<lower=0> sigma; //standard deviation across experiments
}
model {
  // priors
  mu ~ normal(0, 10);
  sigma ~ normal(0, 3);
  // likelihood
  for (i in 1:nexpt) {
	  m[i] ~ normal(mu, sigma);
	  ybar[i] ~ normal(m[i], s[i]/sqrt(nobs[i])); 
  }
}
```

## Fit hierarchical model to past experiments
```{r, include=FALSE}
lr <- read.csv("display_LewisRao2015Retail.csv")
# data taken from tables 1 and 2 of Lewis and Rao (2015)
c <- c(1:3,5:6) # include only advertiser 1 and eliminate exp 4
d1 <- list(nexpt=length(c), nobs=lr$n1[c], ybar=lr$m[c], s=lr$s[c])
m1 <- stan(file="test_roll_model.stan", data=d1, seed=20030601, 
           iter=10000)
```

## Fitted model
```{r}
summary(m1)$summary
```

## Compute optimal sample size
```{r}
mu <- 10.36044
sigma <- 4.39646
margin <- 0.5
(s <- mean(d1$s))
(d <- mean(lr$cost[c])/margin)
N <- 1000000
(n <- test_size_nn(N, s, mu, sigma))
```

## Evaluate the test
(eval <- test_eval_nn(n, N, s, mu, sigma))

## Compare to hypothesis test 
Null hypothesis test size to detect ROI = 0 versus ROI = -100
```{r}
(n_nht <- test_size_nht(s=s, d=d))  
test_eval_nn(n_nht, N, s, mu, sigma)
```

# Compare to hypothesis test with finite population correction
(n_fpc <- test_size_nht(s=s, d=d, N=N))  
(eval_fpc <- test_eval_nn(c(n_fpc, n_fpc), N, s, mu, sigma))


# Multi-armed bandits

## Multi-armed bandits
Using multi-armed bandits are a dynamic
